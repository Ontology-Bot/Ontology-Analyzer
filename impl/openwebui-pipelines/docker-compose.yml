services:
  pipelines:
    image: ghcr.io/open-webui/pipelines:main
    container_name: pipelines
    volumes:
      - ./app/pipelines:/app/pipelines
      - ./app/prototypes:/app/prototypes
    ports:
      - "9099:9099"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      PIPELINES_API_KEY: free_pass # any string, will be used to add pipelines to webui
      LLM_PROVIDER: "openai_compat" # switch to "ollama" for Uni endpoint
      LLM_BASE_URL: "https://chat-ai.academiccloud.de/v1/"
      LLM_API_KEY: ""
      LLM_DEFAULT_MODEL: "openai-gpt-oss-120b"
      SPARQL_BASE_URL: "http://172.17.0.1:7200/repositories/ontobot"
    restart: unless-stopped

volumes:
  pipelines:
